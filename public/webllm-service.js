/**
 * WebLLM Service - TarayÄ±cÄ±da Tamamen Offline AI
 * 
 * WebLLM kullanarak tarayÄ±cÄ±da yerel olarak AI modeli Ã§alÄ±ÅŸtÄ±rÄ±r.
 * Avantajlar:
 * - âœ… Tamamen Ã¼cretsiz (API key gerekmez)
 * - âœ… Tamamen offline (internet gerekmez)
 * - âœ… Gizlilik (veriler tarayÄ±cÄ±da kalÄ±r)
 * - âœ… HÄ±zlÄ± yanÄ±tlar (API beklemeden)
 * 
 * Desteklenen Modeller:
 * - Llama-3.1-8B (Ã–nerilen)
 * - Phi-3-mini-4k
 * - TinyLlama-1.1B
 * - Mistral-7B
 */

class WebLLMService {
    constructor() {
        this.engine = null;
        this.isLoading = false;
        this.isReady = false;
        this.selectedModel = 'Phi-3-mini-4k-instruct-q4f16_1-MLC'; // KÃ¼Ã§Ã¼k ve hÄ±zlÄ± model (2.4GB)
        this.progressCallback = null;
        
        console.log('ğŸ¤– WebLLM Service oluÅŸturuldu');
    }
    
    /**
     * WebLLM motorunu baÅŸlat ve modeli yÃ¼kle
     */
    async initialize(progressCallback) {
        if (this.isReady) {
            console.log('âœ… WebLLM zaten hazÄ±r');
            return true;
        }
        
        if (this.isLoading) {
            console.log('â³ WebLLM yÃ¼kleniyor, lÃ¼tfen bekleyin...');
            return false;
        }
        
        this.isLoading = true;
        this.progressCallback = progressCallback;
        
        try {
            console.log('ğŸ“¦ WebLLM kÃ¼tÃ¼phanesi yÃ¼kleniyor...');
            
            // WebLLM'i import et
            if (!window.mlc) {
                console.log('ğŸ“¦ WebLLM yÃ¼kleniyor...');
                const { CreateMLCEngine } = await import("https://esm.run/@mlc-ai/web-llm");
                window.CreateMLCEngine = CreateMLCEngine;
                console.log('âœ… WebLLM import edildi');
            }
            
            console.log('ğŸš€ WebLLM motoru baÅŸlatÄ±lÄ±yor...');
            console.log('ğŸ“¦ Model:', this.selectedModel);
            
            // Model yÃ¼kleme ilerlemesini gÃ¶ster
            const initProgressCallback = (report) => {
                console.log('ğŸ“Š Model yÃ¼kleme:', report);
                if (this.progressCallback) {
                    this.progressCallback(report);
                }
            };
            
            // Timeout ekle (2 dakika)
            const timeoutPromise = new Promise((_, reject) => {
                setTimeout(() => reject(new Error('Model yÃ¼kleme zaman aÅŸÄ±mÄ± (2 dakika)')), 120000);
            });
            
            // Engine oluÅŸtur (timeout ile)
            this.engine = await Promise.race([
                window.CreateMLCEngine(
                    this.selectedModel,
                    { 
                        initProgressCallback: initProgressCallback,
                        logLevel: 'INFO'
                    }
                ),
                timeoutPromise
            ]);
            
            this.isReady = true;
            this.isLoading = false;
            
            console.log('âœ… WebLLM hazÄ±r!');
            return true;
            
        } catch (error) {
            console.error('âŒ WebLLM baÅŸlatma hatasÄ±:', error);
            console.error('Hata detayÄ±:', {
                message: error.message,
                stack: error.stack,
                name: error.name
            });
            
            // WebGPU kontrolÃ¼
            if (navigator.gpu) {
                console.log('âœ… WebGPU mevcut');
            } else {
                console.error('âŒ WebGPU YOK! chrome://flags/#enable-unsafe-webgpu aÃ§Ä±n');
            }
            
            this.isLoading = false;
            this.isReady = false;
            
            // KullanÄ±cÄ±ya hata mesajÄ±
            if (this.progressCallback) {
                this.progressCallback({
                    text: 'HATA: ' + error.message,
                    progress: 0
                });
            }
            
            return false;
        }
    }

    
    /**
     * Sohbet mesajÄ± gÃ¶nder
     */
    async chat(message, conversationHistory = []) {
        if (!this.isReady) {
            throw new Error('WebLLM hazÄ±r deÄŸil. Ã–nce initialize() Ã§aÄŸÄ±rÄ±n.');
        }
        
        try {
            console.log('ğŸ’¬ Mesaj gÃ¶nderiliyor:', message);
            
            // Mesaj formatÄ±nÄ± oluÅŸtur
            const messages = [
                {
                    role: 'system',
                    content: 'Sen Tercih AI\'sÄ±n. TÃ¼rk Ã¶ÄŸrencilere Ã¼niversite tercihi konusunda yardÄ±mcÄ± oluyorsun. CevaplarÄ±nÄ± TÃ¼rkÃ§e ver.'
                },
                ...conversationHistory,
                {
                    role: 'user',
                    content: message
                }
            ];
            
            // YanÄ±t al (streaming)
            let fullResponse = '';
            const completion = await this.engine.chat.completions.create({
                messages: messages,
                temperature: 0.7,
                max_tokens: 1000,
                stream: true
            });
            
            // Stream'i oku
            for await (const chunk of completion) {
                const content = chunk.choices[0]?.delta?.content || '';
                fullResponse += content;
                console.log('ğŸ“ Chunk:', content);
            }
            
            console.log('âœ… YanÄ±t tamamlandÄ±:', fullResponse);
            return fullResponse;
            
        } catch (error) {
            console.error('âŒ Chat hatasÄ±:', error);
            throw error;
        }
    }
    
    /**
     * Streaming chat (gerÃ§ek zamanlÄ±)
     */
    async chatStream(message, conversationHistory = [], onChunk) {
        if (!this.isReady) {
            throw new Error('WebLLM hazÄ±r deÄŸil. Ã–nce initialize() Ã§aÄŸÄ±rÄ±n.');
        }
        
        try {
            console.log('ğŸ’¬ Streaming mesaj gÃ¶nderiliyor:', message);
            
            const messages = [
                {
                    role: 'system',
                    content: 'Sen Tercih AI\'sÄ±n. TÃ¼rk Ã¶ÄŸrencilere Ã¼niversite tercihi konusunda yardÄ±mcÄ± oluyorsun. CevaplarÄ±nÄ± TÃ¼rkÃ§e ver. KÄ±sa ve Ã¶z yanÄ±tlar ver.'
                },
                ...conversationHistory,
                {
                    role: 'user',
                    content: message
                }
            ];
            
            let fullResponse = '';
            const completion = await this.engine.chat.completions.create({
                messages: messages,
                temperature: 0.7,
                max_tokens: 1000,
                stream: true
            });
            
            for await (const chunk of completion) {
                const content = chunk.choices[0]?.delta?.content || '';
                if (content) {
                    fullResponse += content;
                    if (onChunk) {
                        onChunk(content, fullResponse);
                    }
                }
            }
            
            return fullResponse;
            
        } catch (error) {
            console.error('âŒ Chat stream hatasÄ±:', error);
            throw error;
        }
    }
    
    /**
     * Ãœniversite analizi yap (Ã¶zel prompt)
     */
    async analyzeUniversityChoice(userData) {
        const prompt = `
Ã–ÄŸrenci Bilgileri:
- TYT SÄ±ralamasÄ±: ${userData.tytRanking}
- AYT SÄ±ralamasÄ±: ${userData.aytRanking}
- Hayalindeki BÃ¶lÃ¼m: ${userData.dreamDept}
- Tercih EttiÄŸi Åehirler: ${userData.cities}
- BulunduÄŸu Ä°l: ${userData.location}

LÃ¼tfen bu Ã¶ÄŸrenciye Ã¼niversite tercihi konusunda rehberlik et. Hangi programlara baÅŸvurabileceÄŸini, alternatif bÃ¶lÃ¼mleri ve stratejik tavsiyeleri ver.
`;
        
        return await this.chat(prompt);
    }
    
    /**
     * Modeli deÄŸiÅŸtir
     */
    async changeModel(modelName) {
        console.log('ğŸ”„ Model deÄŸiÅŸtiriliyor:', modelName);
        
        // Mevcut engine'i temizle
        if (this.engine) {
            this.engine = null;
        }
        
        this.isReady = false;
        this.selectedModel = modelName;
        
        // Yeni modeli yÃ¼kle
        return await this.initialize(this.progressCallback);
    }
    
    /**
     * KullanÄ±labilir modelleri listele
     */
    getAvailableModels() {
        return [
            {
                id: 'Llama-3.1-8B-Instruct-q4f32_1-MLC',
                name: 'Llama 3.1 8B',
                size: '4.8 GB',
                description: 'YÃ¼ksek kaliteli, dengeli performans (Ã–nerilen)',
                recommended: true
            },
            {
                id: 'Phi-3-mini-4k-instruct-q4f16_1-MLC',
                name: 'Phi-3 Mini',
                size: '2.4 GB',
                description: 'KÃ¼Ã§Ã¼k boyut, hÄ±zlÄ± yanÄ±t',
                recommended: false
            },
            {
                id: 'TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC',
                name: 'TinyLlama 1.1B',
                size: '800 MB',
                description: 'Ã‡ok hafif, dÃ¼ÅŸÃ¼k donanÄ±m iÃ§in',
                recommended: false
            }
        ];
    }
    
    /**
     * Bellek kullanÄ±mÄ±nÄ± kontrol et
     */
    getMemoryUsage() {
        if (performance.memory) {
            return {
                used: (performance.memory.usedJSHeapSize / 1024 / 1024).toFixed(2) + ' MB',
                total: (performance.memory.totalJSHeapSize / 1024 / 1024).toFixed(2) + ' MB',
                limit: (performance.memory.jsHeapSizeLimit / 1024 / 1024).toFixed(2) + ' MB'
            };
        }
        return null;
    }
    
    /**
     * Engine'i temizle
     */
    cleanup() {
        if (this.engine) {
            console.log('ğŸ§¹ WebLLM temizleniyor...');
            this.engine = null;
            this.isReady = false;
        }
    }
}

// Global instance oluÅŸtur
window.webLLMService = new WebLLMService();

// Export
if (typeof module !== 'undefined' && module.exports) {
    module.exports = WebLLMService;
}
